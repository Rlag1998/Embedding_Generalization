{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68750c4a",
   "metadata": {},
   "source": [
    "# Generalization of Quantum Metric Learning Classifiers (Breast Cancer Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33344c25",
   "metadata": {},
   "source": [
    "*Adapted from work authored by Maria Schuld and Aroosa Ijaz*\n",
    "\n",
    "*Authors: Jonathan Kim and Stefan Bekiranov*\n",
    "\n",
    "This tutorial uses the idea of quantum embeddings for metric learning presented in \n",
    "[Lloyd, Schuld, Ijaz, Izaac, Killoran (2020)](https://arxiv.org/abs/2001.03622) \n",
    "by training a hybrid classical-quantum data embedding to classify breast cancer data. \n",
    "Lloyd et al.'s approach was inspired by [Mari et al. (2019)](https://arxiv.org/abs/1912.08278) \n",
    "(see also this [tutorial](https://pennylane.ai/qml/demos/tutorial_quantum_transfer_learning.html)). \n",
    "This tutorial and its corresponding preparation steps (as included in the ``cancer_general.py`` and \n",
    "``cancer_non-PCA.py`` files in the [embedding_metric_learning folder](https://github.com/Rlag1998/Embedding_Generalization/tree/main/embedding_metric_learning)) \n",
    "adapts the work of Lloyd et al. by changing the data pre-processing steps, including the use of principal component analysis for feature reduction. \n",
    "This tutorial aims to produce good generalization peformance for test set data (something that \n",
    "was not demonstrated in the original quantum metric learning code).\n",
    "\n",
    "More details on this topic can be found in the research paper, [Generalization Performance of Quantum Metric Learning Classifiers](https://doi.org/10.3390/biom12111576). \n",
    "\n",
    "Illustrated below is the general circuit used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59757b2",
   "metadata": {},
   "source": [
    "<img src=\"embedding_metric_learning/classification.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b3e7ef",
   "metadata": {},
   "source": [
    "After any linear pre-processing steps, ``n`` input features are reduced via matrix multiplication \n",
    "to ``x1``, ``x2`` intermediate values, which are then fed into a quantum feature map consisting of ZZ \n",
    "entanglers, as well as RX and RY rotational gates. This results in ``2n + 12`` total parameters \n",
    "(``2n`` from the classical part, ``12`` from the quantum feature map) which are trained and updated over \n",
    "a set number of iterations, resulting in a trained embedding. The trained embedding is able to embed \n",
    "input datapoints in Hilbert space such that the Hilbert-Schmidt distance between datapoints of different \n",
    "classes is maximized. A linear decision boundary can then be drawn across the datapoints in Hilbert space, \n",
    "which corresponds to a complex decision boundary in classical space. This form of embedding training is \n",
    "known as Quantum Metric Learning.\n",
    "\n",
    "Through explorations with the ImageNet Ants & Bees image dataset, we find that datasets with too many features \n",
    "show poor generalization when using this method. In this demo, we instead use a breast cancer dataset with \n",
    "just 30 features per sample.\n",
    "\n",
    "Let us begin!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086e19d7",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d1f250",
   "metadata": {},
   "source": [
    "The tutorial requires the following imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4133cb20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rlagu\\anaconda3\\lib\\site-packages\\_distutils_hack\\__init__.py:30: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane import RX, RY, RZ, CNOT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87f9167",
   "metadata": {},
   "source": [
    "The following random seed is used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b63bcb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3f7bb2",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241e91ae",
   "metadata": {},
   "source": [
    "Quantum metric learning is used to train a quantum embedding, which is \n",
    "used for classifying data. Quantum embeddings are learned by maximizing \n",
    "Hilbert-Schmidt distances of datapoints from two classes. After training, \n",
    "datapoints of different classes become maximally separated in Hilbert \n",
    "space. This results in a simple linear decision boundary in Hilbert space \n",
    "which represents a complex decision boundary in the original feature space.\n",
    "\n",
    "A cost function is used to track the progress of the training; the lower \n",
    "the cost function, the greater the class separation in Hilbert space.\n",
    "\n",
    "The model is ultimately optimized with the ``RMSPropOptimizer`` and data are \n",
    "classified according to a KNN-style classifier.\n",
    "\n",
    "Below is the code that makes up the quantum feature map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6eae78a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_encoding_hamiltonian(features, wires):\n",
    "\n",
    "    for idx, w in enumerate(wires):\n",
    "        RX(features[idx], wires=w)\n",
    "\n",
    "\n",
    "def ising_hamiltonian(weights, wires, l):\n",
    "\n",
    "    # ZZ coupling\n",
    "    CNOT(wires=[wires[1], wires[0]])\n",
    "    RZ(weights[l, 0], wires=wires[0])\n",
    "    CNOT(wires=[wires[1], wires[0]])\n",
    "    # local fields\n",
    "    for idx, w in enumerate(wires):\n",
    "        RY(weights[l, idx + 1], wires=w)\n",
    "\n",
    "\n",
    "def QAOAEmbedding(features, weights, wires):\n",
    "\n",
    "    repeat = len(weights)\n",
    "    for l in range(repeat):\n",
    "        # apply alternating Hamiltonians\n",
    "        feature_encoding_hamiltonian(features, wires)\n",
    "        ising_hamiltonian(weights, wires, l)\n",
    "    # repeat the feature encoding once more at the end\n",
    "    feature_encoding_hamiltonian(features, wires)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbaa3c91",
   "metadata": {},
   "source": [
    "By default, the model has 72 trainable parameters - 30 x 2 for \n",
    "the classical part of the model and 12 for the quantum part.\n",
    "(For an ``n`` number of linear parameters, we have ``2n + 12``\n",
    "total trainable parameters.)\n",
    "\n",
    "The following datafiles were created by normalizing the 30 clinical \n",
    "features of the data, then carrying out principal component analysis \n",
    "on them to reduce the number of trainable parameters. \n",
    "The data preparation code used to create these files can be found in \n",
    "the [embedding_metric_learning folder](https://github.com/Rlag1998/Embedding_Generalization/tree/main/embedding_metric_learning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dc7bdf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127, 4)\n",
      "(214, 4)\n",
      "(85, 4)\n",
      "(143, 4)\n"
     ]
    }
   ],
   "source": [
    "X = np.loadtxt(\"embedding_metric_learning/bc_x_array.txt\", ndmin=2)  # pre-prepared training inputs\n",
    "Y = np.loadtxt(\"embedding_metric_learning/bc_y_array.txt\")  # training labels\n",
    "X_val = np.loadtxt(\n",
    "    \"embedding_metric_learning/bc_x_test_array.txt\", ndmin=2\n",
    ")  # pre-prepared validation inputs\n",
    "Y_val = np.loadtxt(\"embedding_metric_learning/bc_y_test_array.txt\")  # validation labels\n",
    "\n",
    "# split data into two classes\n",
    "A = X[Y == -1]  # benign\n",
    "B = X[Y == 1]  # malignant\n",
    "A_val = X_val[Y_val == -1]\n",
    "B_val = X_val[Y_val == 1]\n",
    "\n",
    "print(A.shape)\n",
    "print(B.shape)\n",
    "print(A_val.shape)\n",
    "print(B_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b12a89f",
   "metadata": {},
   "source": [
    "Quantum node initialization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85718e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 2\n",
    "n_qubits = 2 * n_features + 1\n",
    "\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a63924",
   "metadata": {},
   "source": [
    "SWAP test for overlap measurement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c1b1f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@qml.qnode(dev)\n",
    "def swap_test(q_weights, x1, x2):\n",
    "\n",
    "    # load the two inputs into two different registers\n",
    "    QAOAEmbedding(features=x1, weights=q_weights, wires=[1, 2])\n",
    "    QAOAEmbedding(features=x2, weights=q_weights, wires=[3, 4])\n",
    "\n",
    "    # perform the SWAP test\n",
    "    qml.Hadamard(wires=0)\n",
    "    for k in range(n_features):\n",
    "        qml.CSWAP(wires=[0, k + 1, 2 + k + 1])\n",
    "    qml.Hadamard(wires=0)\n",
    "\n",
    "    return qml.expval(qml.PauliZ(0))\n",
    "\n",
    "\n",
    "def overlaps(weights, X1=None, X2=None):\n",
    "\n",
    "    linear_layer = weights[0]\n",
    "    q_weights = weights[1]\n",
    "\n",
    "    overlap = 0\n",
    "    for x1 in X1:\n",
    "        for x2 in X2:\n",
    "            # multiply the inputs with the linear layer weight matrix\n",
    "            w_x1 = linear_layer @ x1\n",
    "            w_x2 = linear_layer @ x2\n",
    "            # overlap of embedded intermediate features\n",
    "            overlap += swap_test(q_weights, w_x1, w_x2)\n",
    "\n",
    "    mean_overlap = overlap / (len(X1) * len(X2))\n",
    "\n",
    "    return mean_overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52af1e39",
   "metadata": {},
   "source": [
    "Below is the cost function, which takes both inter-cluster overlaps and intra-\n",
    "cluster overlaps into consideration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4b1b01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(weights, A=None, B=None):\n",
    "\n",
    "    aa = overlaps(weights, X1=A, X2=A)\n",
    "    bb = overlaps(weights, X1=B, X2=B)\n",
    "    ab = overlaps(weights, X1=A, X2=B)\n",
    "\n",
    "    d_hs = -2 * ab + (aa + bb)\n",
    "\n",
    "    return 1 - 0.5 * d_hs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977f0f6f",
   "metadata": {},
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b72a7a9",
   "metadata": {},
   "source": [
    "The intial classical and quantum parameters are generated at random.\n",
    "\n",
    "The lattermost integer belonging to the ``size`` attribute of the \n",
    "``init_pars_classical`` variable is changed according to the number of \n",
    "principal components used during data preparation (as determined by \n",
    "the configuration of the data preparation files in the \n",
    "[embedding_metric_learning folder](https://github.com/Rlag1998/Embedding_Generalization/tree/main/embedding_metric_learning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dee5b09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate initial parameters for the quantum component, such that\n",
    "# the resulting number of trainable quantum parameters is equal to\n",
    "# the product of the elements that make up the 'size' attribute\n",
    "# (4 * 3 = 12).\n",
    "init_pars_quantum = np.random.normal(loc=0, scale=0.1, size=(4, 3))\n",
    "\n",
    "# generate initial parameters for the classical component, such that\n",
    "# the resulting number of trainable classical parameters is equal to\n",
    "# the product of the elements that make up the 'size' attribute.\n",
    "init_pars_classical = np.random.normal(loc=0, scale=0.1, size=(2, 4))\n",
    "\n",
    "init_pars = [init_pars_classical, init_pars_quantum]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b22531",
   "metadata": {},
   "source": [
    "The ``RMSPropOptimizer`` is used with a step size of 0.01 and batch size \n",
    "of 5 to optimize the model over 400 iterations. The ``pars`` variable \n",
    "is updated after every iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1181eaec",
   "metadata": {},
   "source": [
    "> ⚠️**Note**⚠️: Despite the code steps shown below, all figure results in this demo were generated with a batch size of 10 over 1500 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d50d94c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = qml.RMSPropOptimizer(stepsize=0.01)\n",
    "batch_size = 5\n",
    "pars = init_pars\n",
    "\n",
    "cost_list = []\n",
    "for i in range(400):\n",
    "\n",
    "    # Sample a batch of training inputs from each class\n",
    "    selectA = np.random.choice(range(len(A)), size=(batch_size,), replace=True)\n",
    "    selectB = np.random.choice(range(len(B)), size=(batch_size,), replace=True)\n",
    "    A_batch = [A[s] for s in selectA]\n",
    "    B_batch = [B[s] for s in selectB]\n",
    "\n",
    "    # Walk one optimization step\n",
    "    pars = optimizer.step(lambda w: cost(w, A=A_batch, B=B_batch), pars)\n",
    "    # print(pars)\n",
    "    # print(\"Step\", i+1, \"done.\")\n",
    "\n",
    "    # Print the validation cost every 10 steps\n",
    "    # if i % 50 == 0 and i != 0:\n",
    "    #    cst = cost(pars, A=A_val, B=B_val)\n",
    "    #    print(\"Cost on validation set {:2f}\".format(cst))\n",
    "    #    cost_list.append(cst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c49fb4a",
   "metadata": {},
   "source": [
    "The quantum and classical parameters are saved into txt files so they may be used at a future time without having to re-train the initial parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42ee73c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantum pars:  [[ 1.84570322  0.05440852  0.25863777]\n",
      " [ 0.1851506   0.14087993 -0.32855462]\n",
      " [ 0.73760758 -0.18347538 -0.84942516]\n",
      " [-0.23045604  0.17332106 -1.04590088]]\n",
      "classical pars:  [[-0.27777109  0.12409376  0.11142132  0.17101765]\n",
      " [ 0.00083786  0.01421777 -0.00297937  0.0040684 ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"quantum pars: \", pars[1])\n",
    "with open(r\"thetas.txt\", \"w\") as file1:\n",
    "    for item in pars[1]:\n",
    "        file1.write(\"%s\\n\" % item)\n",
    "\n",
    "print(\"classical pars: \", pars[0])\n",
    "with open(r\"x1x2.txt\", \"w\") as file2:\n",
    "    for item in pars[0]:\n",
    "        file2.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d22bfaf",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc59448",
   "metadata": {},
   "source": [
    "Hilbert space mutual data overlap gram matrices can be used to assess \n",
    "the separation in embedded test set datapoints. Scatter plots \n",
    "depicting the pre-training and post-training positions of the \n",
    "``x1``, ``x2`` intermediate points can also be plotted.\n",
    "\n",
    "For generating mutual data overlap gram matrices, a smaller subset of \n",
    "the test set data is used, as determined by the ``select`` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdd8241a",
   "metadata": {},
   "outputs": [],
   "source": [
    "select = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb58b51e",
   "metadata": {},
   "source": [
    "Final cost values can be printed out here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "862ab342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost_train = cost(pars, A=A[:select], B=B[:select])\n",
    "# cost_val = cost(pars, A=A_val[:select], B=B_val[:select])\n",
    "\n",
    "\n",
    "# cost_train = cost(pars, A=A, B=B)\n",
    "# cost_val = cost(pars, A=A_val, B=B_val)\n",
    "# print(\"Cost for pretrained parameters on training set:\", cost_train)\n",
    "# print(\"Cost for pretrained parameters on validation set:\", cost_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b840a9",
   "metadata": {},
   "source": [
    "Continuation of gram matrices preparation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e659ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A_B = np.r_[A[:select], B[:select]]\n",
    "A_B = np.r_[A_val[:select], B_val[:select]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b70735",
   "metadata": {},
   "source": [
    "Before training, class separation is not observed within the gram matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0924831c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gram_before = [[overlaps(init_pars, X1=[x1], X2=[x2]) for x1 in A_B] for x2 in A_B]\n",
    "\n",
    "ax = plt.subplot(111)\n",
    "im = ax.matshow(gram_before, vmin=0, vmax=1)\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "plt.colorbar(im, cax=cax)\n",
    "\n",
    "plt.close()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fa6327",
   "metadata": {},
   "source": [
    "<img src=\"embedding_metric_learning/figures/All_Figures/3.5.1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91594983",
   "metadata": {},
   "source": [
    "After training, the goal is for there to be a clear separation between \n",
    "the two classes, such that there are four clearly defined squares of \n",
    "mutual overlap (two yellow, two purple). This desired level of \n",
    "separation has been achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "598d2b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "gram_after = [[overlaps(pars, X1=[x1], X2=[x2]) for x1 in A_B] for x2 in A_B]\n",
    "\n",
    "ax = plt.subplot(111)\n",
    "im = ax.matshow(gram_after, vmin=0, vmax=1)\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "plt.colorbar(im, cax=cax)\n",
    "\n",
    "plt.close()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f6e94d",
   "metadata": {},
   "source": [
    "<img src=\"embedding_metric_learning/figures/All_Figures/3.5.2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d50d6e9",
   "metadata": {},
   "source": [
    "The two-dimensional intermediate (``x1``, ``x2``) points can be graphed in the \n",
    "form of scatter plots to help visualize the separation progress from \n",
    "a different perspective.\n",
    "\n",
    "The code below results in the pre-training scatter plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "826b1a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "blue_patch = mpatches.Patch(color=\"blue\", label=\"Training: Benign\")\n",
    "red_patch = mpatches.Patch(color=\"red\", label=\"Training: Malignant\")\n",
    "cornflowerblue_patch = mpatches.Patch(color=\"cornflowerblue\", label=\"Test: Benign\")\n",
    "lightcoral_patch = mpatches.Patch(color=\"lightcoral\", label=\"Test: Malignant\")\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 8)\n",
    "plt.rc(\"xtick\", labelsize=12)\n",
    "plt.rc(\"ytick\", labelsize=12)\n",
    "\n",
    "for a in A:\n",
    "    intermediate_a = init_pars[0] @ a\n",
    "    plt.scatter(intermediate_a[:][0], intermediate_a[:][1], c=\"blue\")\n",
    "\n",
    "for b in B:\n",
    "    intermediate_b = init_pars[0] @ b\n",
    "    plt.scatter(intermediate_b[:][0], intermediate_b[:][1], c=\"red\")\n",
    "\n",
    "for a in A_val:\n",
    "    intermediate_a = init_pars[0] @ a\n",
    "    plt.scatter(intermediate_a[:][0], intermediate_a[:][1], c=\"cornflowerblue\")\n",
    "\n",
    "for b in B_val:\n",
    "    intermediate_b = init_pars[0] @ b\n",
    "    plt.scatter(intermediate_b[:][0], intermediate_b[:][1], c=\"lightcoral\")\n",
    "\n",
    "plt.xlabel(r\"$x_1$\", fontsize=20)\n",
    "plt.ylabel(r\"$x_2$\", fontsize=20)\n",
    "plt.legend(handles=[blue_patch, cornflowerblue_patch, red_patch, lightcoral_patch], fontsize=12)\n",
    "\n",
    "plt.close()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c37f89c",
   "metadata": {},
   "source": [
    "<img src=\"embedding_metric_learning/figures/All_Figures/3.5.3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfe673f",
   "metadata": {},
   "source": [
    "The below code results in the post-training scatter plot. \n",
    "It is clear that both the training set and set set intermediate values \n",
    "separated reasonably well in two dimensions, an indication of good generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04e7ae6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in A:\n",
    "    intermediate_a = pars[0] @ a\n",
    "    plt.scatter(intermediate_a[:][0], intermediate_a[:][1], c=\"blue\")\n",
    "\n",
    "for b in B:\n",
    "    intermediate_b = pars[0] @ b\n",
    "    plt.scatter(intermediate_b[:][0], intermediate_b[:][1], c=\"red\")\n",
    "\n",
    "for a in A_val:\n",
    "    intermediate_a = pars[0] @ a\n",
    "    plt.scatter(intermediate_a[:][0], intermediate_a[:][1], c=\"cornflowerblue\")\n",
    "\n",
    "for b in B_val:\n",
    "    intermediate_b = pars[0] @ b\n",
    "    plt.scatter(intermediate_b[:][0], intermediate_b[:][1], c=\"lightcoral\")\n",
    "\n",
    "plt.xlabel(r\"$x_1$\", fontsize=20)\n",
    "plt.ylabel(r\"$x_2$\", fontsize=20)\n",
    "plt.legend(handles=[blue_patch, cornflowerblue_patch, red_patch, lightcoral_patch], fontsize=12)\n",
    "\n",
    "plt.close()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b52acf",
   "metadata": {},
   "source": [
    "<img src=\"embedding_metric_learning/figures/All_Figures/3.5.4.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b60db2b",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa020cc",
   "metadata": {},
   "source": [
    "A KNN-style classifier can be used to determine the class for each new \n",
    "datapoint based on the datapoint's degree of overlap with each of the two \n",
    "separated classes of the training set data.\n",
    "\n",
    "Below, test set classification is evaluated by means of a ``predict`` \n",
    "function to yield subsequent F1, precision, recall, accuracy and specificity \n",
    "scores. A confusion matrix of the form (TP, FN, FP, TN) is also returned.\n",
    "As expected, relatively strong classification performance is observed \n",
    "with this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b9a7799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[139, 4, 8, 77]\n",
      "Precision:  0.9455782312925171\n",
      "Recall:  0.972027972027972\n",
      "Accuracy:  0.9473684210526315\n",
      "Specificity:  0.9058823529411765\n",
      "F1 Score:  0.9586206896551724\n"
     ]
    }
   ],
   "source": [
    "def predict(n_samples, pred_low, pred_high, choice):\n",
    "\n",
    "    truepos = 0\n",
    "    falseneg = 0\n",
    "    falsepos = 0\n",
    "    trueneg = 0\n",
    "\n",
    "    for i in range(pred_low, pred_high):\n",
    "        pred = \"\"\n",
    "        if choice == 0:\n",
    "            x_new = A_val[i]  # Benign\n",
    "        else:\n",
    "            x_new = B_val[i]  # Malignant\n",
    "\n",
    "        prediction = 0\n",
    "        for s in range(n_samples):\n",
    "\n",
    "            # select a random sample from the training set\n",
    "            sample_index = np.random.choice(len(X))\n",
    "            x = X[sample_index]\n",
    "            y = Y[sample_index]\n",
    "\n",
    "            # compute the overlap between training sample and new input\n",
    "            overlap = overlaps(pars, X1=[x], X2=[x_new])\n",
    "\n",
    "            # add the label weighed by the overlap to the prediction\n",
    "            prediction += y * overlap\n",
    "\n",
    "        # normalize prediction\n",
    "        prediction = prediction / n_samples\n",
    "\n",
    "        # This component acts as the sign function of this KNN-style method.\n",
    "        # 'Negative' predictions correspond to benign cancers, while 'positive' predictions\n",
    "        # correspond to malignant cancers. The confusion matrix is also constructed here.\n",
    "        if prediction < 0:\n",
    "            pred = \"Benign\"\n",
    "            if choice == 0:\n",
    "                trueneg += 1\n",
    "            else:\n",
    "                falseneg += 1\n",
    "\n",
    "        else:\n",
    "            pred = \"Malignant\"\n",
    "            if choice == 0:\n",
    "                falsepos += 1\n",
    "            else:\n",
    "                truepos += 1\n",
    "        # print(\"prediction: \"+str(pred)+\", value is \"+str(prediction))\n",
    "\n",
    "    # print(truepos, falseneg, falsepos, trueneg)\n",
    "    return truepos, falseneg, falsepos, trueneg\n",
    "\n",
    "\n",
    "totals = [x + y for x, y in zip(predict(20, 0, len(A_val), 0), predict(20, 0, len(B_val), 1))]\n",
    "print(totals)\n",
    "precision = totals[0] / (totals[0] + totals[2])\n",
    "recall = totals[0] / (totals[0] + totals[1])\n",
    "accuracy = (totals[0] + totals[3]) / (totals[0] + totals[1] + totals[2] + totals[3])\n",
    "specificity = totals[3] / (totals[3] + totals[2])\n",
    "\n",
    "f1 = (2 * precision * recall) / (precision + recall)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Specificity: \", specificity)\n",
    "print(\"F1 Score: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7eb5560",
   "metadata": {},
   "source": [
    "Below is an example table of results based on varying the the number of principal components. In each row, training was performed for 1500 iterations with a batch size of 10. The features in row 1 did not undergo PCA, while the features from the rest of the rows did. The optimal value of each column is given in bold:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d64b0b8",
   "metadata": {},
   "source": [
    "| No. of Features | Training Cost | Test Cost | Precision | Recall | F1 Score |\n",
    "|:---------------:|:-------------:|:---------:|:---------:|:------:|:--------:|\n",
    "|        30       |     0.2026    |   0.2791  |   0.9205  | 0.9720 |  0.9456  |\n",
    "|        30       |     **0.1750**    |   0.2899  |   0.9211  | 0.9790 |  0.9492  |\n",
    "|        16       |     0.2201    |   0.3101  |   0.9281  | **0.9930** |  0.9595  |\n",
    "|        8        |     0.2497    |   **0.2646**  |   **0.9655**  | 0.9790 |  **0.9722**  |\n",
    "|        4        |     0.2885    |   0.2913  |   0.9467  | **0.9930** |  0.9693  |\n",
    "|        2        |     0.3450    |   0.3306  |   0.9517  | 0.9650 |  0.9583  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894060d9",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b7ea74",
   "metadata": {},
   "source": [
    "Seth Lloyd, Maria Schuld, Aroosa Ijaz, Josh Izaac, Nathan Killoran: \"Quantum embeddings for machine learning\" \n",
    "arXiv preprint arXiv:2001.03622.\n",
    "\n",
    "Andrea Mari, Thomas R. Bromley, Josh Izaac, Maria Schuld, Nathan Killoran: \"Transfer learning \n",
    "in hybrid classical-quantum neural networks\" arXiv preprint arXiv:1912.08278.\n",
    "\n",
    "Jonathan Kim and Stefan Bekiranov: \"Generalization performance of quantum metric learning classifiers\",  \n",
    "https://doi.org/10.3390/biom12111576."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
